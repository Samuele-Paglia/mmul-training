# https://blog.centos.org/2018/11/okd-v3-11-packages-now-available/

# Which gets you basically to:
sudo yum localinstall http://mirror.centos.org/centos/7/extras/x86_64/Packages/centos-release-openshift-origin311-1-2.el7.centos.noarch.rpm

# First you'll need this package:
sudo yum install openshift-ansible

# You must configure the installer node to connect on all other nodes
# with ssh without password

# Then every host (master and nodes) needs NetworkManager and docker
sudo yum install -y NetworkManager docker
sudo systemctl start NetworkManager
sudo systemctl enable NetworkManager
sudo systemctl start docker
sudo systemctl enable docker

# Also, every host network must be managed with NetworkManager. So,
# edit your /etc/sysconfig/network-scripts/ifcfg- configuration file
# adding

NM_CONTROLLED=yes

# Another prerequisite is that every host must use a DNS who can resolve
# the host names and the first host in the subnet

# Then a start inventory to customize, like:
sudo cp /usr/share/doc/openshift-ansible-docs-3.11.37/docs/example-inventories/hosts.example inventory

# Or create a simple one like this

### Specify subgroup of all cluster components (master, nodes, etcd cluster)
[OSEv3:children]
masters
nodes
etcd

### Define some vars, like cluster version or check skipping
[OSEv3:vars]
# admin user created in previous section
ansible_ssh_user=root
ansible_become=false
openshift_deployment_type=origin
openshift_release=v3.11.0
openshift_image_tag=v3.11.0
openshift_disable_check=disk_availability,memory_availability,package_version

### Define authentication method (like htpasswd, LDAP, etc.)
# use HTPasswd for authentication
openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]

### Network configuration (subdomain for OpenShift and connections kind)
# define default sub-domain for Master node
openshift_master_default_subdomain=apps.test.mmul.local
# allow unencrypted connection within cluster
openshift_docker_insecure_registries=172.30.0.0/16

### List the cluster master nodes
[masters]
oc-master.test.mmul.local openshift_schedulable=true containerized=false

### List the etcd cluster nodes
[etcd]
oc-master.test.mmul.local

### List the cluster node nodes
[nodes]
# defined values for [openshift_node_group_name] in the file below
# [/usr/share/ansible/openshift-ansible/roles/openshift_facts/defaults/main.yml]
oc-master.test.mmul.local openshift_node_group_name='node-config-master-infra'
oc-node-1.test.mmul.local openshift_node_group_name='node-config-compute'
oc-node-2.test.mmul.local openshift_node_group_name='node-config-compute'

### Then run prerequisite checks
[root@deployer ~]# ansible-playbook -i inventory /usr/share/ansible/openshift-ansible/playbooks/prerequisites.yml

### Recently, prerequisites can fail with message:
fatal: [oc-node-1.test.mmul.local]: FAILED! => {"attempts": 3, "changed": false, "msg": "No package matching 'python-docker' found available, installed or updated", "rc": 126, "results": ["python-ipaddress-1.0.16-2.el7.noarch providing python-ipaddress is already installed", "iproute-4.11.0-14.el7.x86_64 providing iproute is already installed", "dbus-python-1.1.1-9.el7.x86_64 providing dbus-python is already installed", "PyYAML-3.10-11.el7.x86_64 providing PyYAML is already installed", "libsemanage-python-2.5-14.el7.x86_64 providing libsemanage-python is already installed", "yum-utils-1.1.31-50.el7.noarch providing yum-utils is already installed", "No package matching 'python-docker' found available, installed or updated"]}
# in this case you must edit /usr/share/ansible/openshift-ansible/playbooks/init/base_packages.yml and replace python-docker with python-docker-py
# (https://github.com/openshift/openshift-ansible/issues/10440)

### Then deploy the cluster
[root@deployer ~]# ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/deploy_cluster.yml

### Once deployed, configure the system:admin user
# As the system:admin user, add the cluster-admin role to the admin user, so it will be able to manage the cluster
[root@master ~]# oc adm policy add-cluster-role-to-user cluster-admin admin

### NOTE: When you choose an authentication method (like htpasswd), when you define the first user on that
### the internal admin user of OpenShift will stop working. Remeber to redefine admin user on your htpasswd (or
### other method) and applying on that the admin role before logging out from your cluster

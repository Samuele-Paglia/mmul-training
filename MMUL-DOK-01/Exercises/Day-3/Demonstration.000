# Demonstration 000 - Installing OpenShift on MMUL Infrastructure

0) Steps must be run from a jump host that will be able to access to all the 
   OpenShift nodes, so you must configure the installer node to connect on all
   other nodes with ssh without password;

1) Availability of CentOS packages is announced through the CentOS Blog:

https://blog.centos.org/2018/11/okd-v3-11-packages-now-available/

Which gets you to download and install the base repository package:

[root@oc-services ~]# sudo yum localinstall http://mirror.centos.org/centos/7/extras/x86_64/Packages/centos-release-openshift-origin311-1-2.el7.centos.noarch.rpm

2) First you'll need to install the openshift-ansible package:

[root@oc-services ~]# sudo yum install openshift-ansible

3) Every host (master and nodes) needs NetworkManager and docker

[root@oc-services ~]# sudo yum install -y NetworkManager docker
[root@oc-services ~]# sudo systemctl start NetworkManager
[root@oc-services ~]# sudo systemctl enable NetworkManager
[root@oc-services ~]# sudo systemctl start docker
[root@oc-services ~]# sudo systemctl enable docker

Also, every host network must be managed with NetworkManager. So, edit your
/etc/sysconfig/network-scripts/ifcfg- configuration file adding

NM_CONTROLLED=yes

4) Every host must use a DNS who can resolve the host names and the first host
   in the subnet. Entries in /etc/hosts are NOT ENOUGH.

5) Finally, you'll need a start inventory to customize:

[root@oc-services ~]# sudo cp /usr/share/doc/openshift-ansible-docs-3.11.37/docs/example-inventories/hosts.example inventory

Or create a simple one like this

### Start ###

### Specify subgroup of all cluster components (master, nodes, etcd cluster)
[OSEv3:children]
masters
nodes
etcd

### Define some vars, like cluster version or check skipping
[OSEv3:vars]
# admin user created in previous section
ansible_ssh_user=root
ansible_become=false
openshift_deployment_type=origin
openshift_release=v3.11.0
openshift_image_tag=v3.11.0
openshift_disable_check=disk_availability,memory_availability,package_version

### Define authentication method (like htpasswd, LDAP, etc.)
# use HTPasswd for authentication
openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]

### Network configuration (subdomain for OpenShift and connections kind)
# define default sub-domain for Master node
openshift_master_default_subdomain=apps.test.mmul.local
# allow unencrypted connection within cluster
openshift_docker_insecure_registries=172.30.0.0/16

### List the cluster master nodes
[masters]
oc-master.test.mmul.local openshift_schedulable=true containerized=false

### List the etcd cluster nodes
[etcd]
oc-master.test.mmul.local

### List the cluster node nodes
[nodes]
# defined values for [openshift_node_group_name] in the file below
# [/usr/share/ansible/openshift-ansible/roles/openshift_facts/defaults/main.yml]
oc-master.test.mmul.local openshift_node_group_name='node-config-master-infra'
oc-node-1.test.mmul.local openshift_node_group_name='node-config-compute'
oc-node-2.test.mmul.local openshift_node_group_name='node-config-compute'

### EOF ###

6) Before effectively installing the environment you should run the
   prerequisite checks:

[root@oc-services ~]# ansible-playbook -i inventory /usr/share/ansible/openshift-ansible/playbooks/prerequisites.yml

Recently, prerequisites can fail with message:

fatal: [oc-node-1.test.mmul.local]: FAILED! => {"attempts": 3, "changed": false, "msg": "No package matching 'python-docker' found available, installed or updated", "rc": 126, "results": ["python-ipaddress-1.0.16-2.el7.noarch providing python-ipaddress is already installed", "iproute-4.11.0-14.el7.x86_64 providing iproute is already installed", "dbus-python-1.1.1-9.el7.x86_64 providing dbus-python is already installed", "PyYAML-3.10-11.el7.x86_64 providing PyYAML is already installed", "libsemanage-python-2.5-14.el7.x86_64 providing libsemanage-python is already installed", "yum-utils-1.1.31-50.el7.noarch providing yum-utils is already installed", "No package matching 'python-docker' found available, installed or updated"]}

In this case, as explained here [1], you must edit:

/usr/share/ansible/openshift-ansible/playbooks/init/base_packages.yml

and replace python-docker with python-docker-py

7) Finally, you can deploy the cluster:

[root@oc-services ~]# ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/deploy_cluster.yml

The process should end with something like this:

INSTALLER STATUS **************************************************************
Initialization               : Complete (0:00:18)                                                                                                                                            
Health Check                 : Complete (0:00:33)                                                                                                                                            
Node Bootstrap Preparation   : Complete (0:03:18)                                                                                                                                            
etcd Install                 : Complete (0:00:35)                                                                                                                                            
Master Install               : Complete (0:03:58)                                                                                                                                            
Master Additional Install    : Complete (0:00:28)                                                                                                                                            
Node Join                    : Complete (0:00:12)                                                                                                                                            
Hosted Install               : Complete (0:00:44)                                                                                                                                            
Cluster Monitoring Operator  : Complete (0:01:11)                                                                                                                                            
Web Console Install          : Complete (0:00:30)                                                                                                                                            
Console Install              : Complete (0:00:24)                                                                                                                                            
metrics-server Install       : Complete (0:00:00)                                                                                                                                            
Service Catalog Install      : Complete (0:01:45)

8) Last step is to configure the system:admin user. As the system:admin user,
add the cluster-admin role to the admin user, so it will be able to manage the
cluster. This command must be ran from the master node:

[root@master ~]# oc adm policy add-cluster-role-to-user cluster-admin admin

[1] https://github.com/openshift/openshift-ansible/issues/10440
